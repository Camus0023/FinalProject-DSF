"""
Sistema de Soporte a la Decisi√≥n - Dashboard Inteligente
An√°lisis de Mercado Inmobiliario con IA

Universidad EAFIT | Fundamentos de Ciencia de Datos
Autor: Juan Rua
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import json
import requests
import os
from io import StringIO
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Importar configuraci√≥n espec√≠fica para Streamlit
try:
    from streamlit_config import check_dependencies, get_data_path
except ImportError:
    # Fallback si hay problemas con el import
    def check_dependencies():
        return []
    def get_data_path():
        return "data/data_imperfecto_v2.csv"

# ============================================================================
# CONFIGURACI√ìN DE LA P√ÅGINA
# ============================================================================
st.set_page_config(
    page_title="Dashboard Inmobiliario | EAFIT",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# FUNCIONES AUXILIARES
# ============================================================================
def remove_duplicates(df):
    """Elimina filas duplicadas"""
    initial_rows = len(df)
    df = df.drop_duplicates()
    removed = initial_rows - len(df)
    return df, removed

def impute_missing_values(df, method):
    """Imputa valores faltantes en columnas num√©ricas"""
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    imputed_count = 0
    
    for col in numeric_cols:
        null_count = df[col].isnull().sum()
        if null_count > 0:
            if method == "Media":
                df[col] = df[col].fillna(df[col].mean())
            elif method == "Mediana":
                df[col] = df[col].fillna(df[col].median())
            elif method == "Cero":
                df[col] = df[col].fillna(0)
            imputed_count += null_count
    
    return df, imputed_count

def detect_outliers(df, column):
    """Detecta outliers usando el m√©todo IQR"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]
    return outliers, lower_bound, upper_bound

def treat_outliers(df, column, method):
    """Trata outliers seg√∫n el m√©todo seleccionado"""
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    if method == "Eliminar":
        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    elif method == "Reemplazar con l√≠mites":
        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)
    elif method == "Reemplazar con mediana":
        median = df[column].median()
        df.loc[(df[column] < lower_bound) | (df[column] > upper_bound), column] = median
    
    return df

def create_calculated_features(df):
    """Crea nuevas columnas calculadas (Feature Engineering)"""
    new_features = []
    
    # Precio por pie cuadrado
    if 'price' in df.columns and 'sqft_living' in df.columns:
        df['precio_por_sqft'] = df['price'] / df['sqft_living'].replace(0, np.nan)
        new_features.append('precio_por_sqft')
    
    # Ratio de ba√±os por habitaci√≥n
    if 'bathrooms' in df.columns and 'bedrooms' in df.columns:
        df['ratio_banos_habitaciones'] = df['bathrooms'] / df['bedrooms'].replace(0, np.nan)
        new_features.append('ratio_banos_habitaciones')
    
    # Edad de la propiedad
    if 'yr_built' in df.columns:
        current_year = datetime.now().year
        df['edad_propiedad'] = current_year - df['yr_built']
        new_features.append('edad_propiedad')
    
    # Fue renovada (booleano)
    if 'yr_renovated' in df.columns:
        df['fue_renovada'] = (df['yr_renovated'] > 0).astype(int)
        new_features.append('fue_renovada')
    
    # Extraer mes y a√±o si hay fecha
    if 'date' in df.columns:
        try:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            df['mes'] = df['date'].dt.month
            df['anio'] = df['date'].dt.year
            new_features.extend(['mes', 'anio'])
        except:
            pass
    
    return df, new_features

def generate_ai_insights(df, api_key, custom_prompt=None):
    """Genera insights usando la API de Groq"""
    try:
        # Preparar resumen estad√≠stico
        stats_summary = df.describe().to_string() if not df.empty else "No hay datos estad√≠sticos"
        
        # Informaci√≥n adicional
        null_info = df.isnull().sum().to_string() if not df.empty else "No hay informaci√≥n de nulos"
        
        # Usar prompt personalizado o el predeterminado
        if custom_prompt:
            prompt = f"""{custom_prompt}
            
            DATOS ESTAD√çSTICOS:
            {stats_summary}
            
            INFORMACI√ìN DE VALORES FALTANTES:
            {null_info}
            
            Responde en espa√±ol de forma clara y pr√°ctica, enfocado en decisiones de negocio.
            """
        else:
            # Prompt estructurado predeterminado
            prompt = f"""Eres un analista inmobiliario experto. 
            Analiza los siguientes datos de propiedades y proporciona insights comerciales valiosos.
            
            RESUMEN ESTAD√çSTICO:
            {stats_summary}
            
            VALORES FALTANTES:
            {null_info}
            
            Por favor proporciona un an√°lisis orientado al negocio con:
            1. **Oportunidades de inversi√≥n** que detectas en los datos
            2. **Riesgos potenciales** para compradores e inversionistas
            3. **Tendencias del mercado** basadas en los patrones
            4. **Recomendaciones espec√≠ficas** para diferentes tipos de compradores (primera vivienda, inversi√≥n, lujo)
            
            Responde en espa√±ol de forma clara y pr√°ctica, usando vi√±etas cuando sea apropiado.
            Enf√≥cate en insights que sean √∫tiles para tomar decisiones de compra/venta/inversi√≥n."""
        
        # Llamada a la API de Groq
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": "llama-3.1-70b-versatile",
            "messages": [
                {"role": "system", "content": "Eres un analista inmobiliario experto especializado en asesorar decisiones de inversi√≥n."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 2000
        }
        
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            return result["choices"][0]["message"]["content"], None
        else:
            return None, f"Error API: {response.status_code} - {response.text}"
            
    except Exception as e:
        return None, str(e)

# ============================================================================
# SIDEBAR - NAVEGACI√ìN Y CONFIGURACI√ìN
# ============================================================================
with st.sidebar:
    st.image("https://www.eafit.edu.co/PublishingImages/logosimbolo-eafit.png", width=200)
    st.title("üè† Dashboard Inmobiliario")
    st.markdown("---")
    
    # Navegaci√≥n por m√≥dulos
    modulo = st.radio(
        "üìå Navegaci√≥n",
        ["üîÑ ETL - Carga y Limpieza", "üìä EDA - Visualizaciones", "üîç VERIFICACI√ìN (Temporal)", "ü§ñ IA - Insights Inteligentes"],
        index=0
    )
    
    st.markdown("---")
    st.markdown("### üéØ Preguntas de Negocio Reales")
    st.markdown("""
    1. ¬øD√≥nde invertir para obtener mejor retorno?
    2. ¬øCu√°l es el precio ideal de mi propiedad?  
    3. ¬øQu√© zonas est√°n subvaloradas?
    4. ¬øQu√© tipo de propiedades son m√°s rentables?
    """)
    
    st.markdown("---")
    st.markdown("##### üìö EAFIT 2026-1")
    st.markdown("Fundamentos de Ciencia de Datos")

# ============================================================================
# INICIALIZACI√ìN DEL ESTADO
# ============================================================================
if 'df_original' not in st.session_state:
    st.session_state.df_original = None
if 'df_clean' not in st.session_state:
    st.session_state.df_clean = None
if 'new_features' not in st.session_state:
    st.session_state.new_features = []

# ============================================================================
# M√ìDULO 1: ETL - INGESTA Y PROCESAMIENTO
# ============================================================================
if modulo == "üîÑ ETL - Carga y Limpieza":
    st.title("üîÑ M√≥dulo ETL: Ingesta y Procesamiento de Datos")
    st.markdown("Carga, limpia y transforma tus datos de propiedades inmobiliarias.")
    
    # ----- SECCI√ìN DE CARGA -----
    st.header("üìÅ 1. Carga de Datos")
    st.markdown("**Dataset:** Propiedades inmobiliarias de Washington State, USA")
    
    df = None
    error_msg = None
    
    # Cargar autom√°ticamente el dataset del proyecto
    try:
        data_path = get_data_path()
        df = pd.read_csv(data_path)
        st.success("‚úÖ Dataset cargado correctamente: data_imperfecto_v2.csv")
        st.info("üìä Este dataset contiene datos reales de propiedades inmobiliarias con imperfecciones para demostrar el proceso completo de ETL")
    except Exception as e:
        error_msg = f"Error al cargar el dataset del proyecto: {str(e)}"
        st.error(f"‚ùå No se pudo cargar el archivo de datos. {error_msg}")
        st.stop()
    
    if df is not None:
        st.session_state.df_original = df.copy()
        
        # Mostrar informaci√≥n b√°sica
        st.success(f"‚úÖ Datos cargados: {df.shape[0]:,} filas √ó {df.shape[1]} columnas")
        
        with st.expander("üëÅÔ∏è Vista previa de datos crudos"):
            st.dataframe(df.head(10), use_container_width=True)
        
        with st.expander("üìã Informaci√≥n del Dataset"):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total Filas", f"{df.shape[0]:,}")
            with col2:
                st.metric("Total Columnas", df.shape[1])
            with col3:
                st.metric("Valores Nulos", df.isnull().sum().sum())
            
            st.markdown("**Tipos de datos:**")
            st.dataframe(df.dtypes.astype(str).reset_index().rename(
                columns={'index': 'Columna', 0: 'Tipo'}
            ), use_container_width=True)
        
        # ----- SECCI√ìN DE LIMPIEZA AUTOM√ÅTICA -----
        st.markdown("---")
        st.header("üßπ 2. Limpieza Autom√°tica de Datos")
        
        st.markdown("**¬øQu√© estamos haciendo?** Limpiando autom√°ticamente todos los datos para que est√©n listos para el an√°lisis.")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Propiedades en total", len(df))
        with col2:
            st.metric("Informaci√≥n disponible", len(df.columns))
        with col3:
            problemas = df.isnull().sum().sum() + len(df[df.duplicated()])
            st.metric("Problemas detectados", problemas)
        
        # Ejecutar limpieza autom√°tica
        with st.spinner("Limpiando datos autom√°ticamente..."):
            df_original_etl = df.copy()
            df_clean = df.copy()
            cleaning_steps = []
            
            # 1. Eliminar duplicados
            duplicados_antes = len(df_clean[df_clean.duplicated()])
            df_clean = df_clean.drop_duplicates()
            duplicados_eliminados = duplicados_antes
            if duplicados_eliminados > 0:
                cleaning_steps.append(f"‚úÖ Se eliminaron {duplicados_eliminados} propiedades duplicadas")
            
            # 2. Limpiar valores nulos de forma inteligente
            nulos_antes = df_clean.isnull().sum().sum()
            
            # Para columnas num√©ricas: rellenar con la mediana
            numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if df_clean[col].isnull().sum() > 0:
                    df_clean[col] = df_clean[col].fillna(df_clean[col].median())
            
            # Para columnas de texto: rellenar con 'No especificado'
            text_cols = df_clean.select_dtypes(include=['object']).columns
            for col in text_cols:
                if df_clean[col].isnull().sum() > 0:
                    df_clean[col] = df_clean[col].fillna('No especificado')
            
            nulos_despues = df_clean.isnull().sum().sum()
            nulos_corregidos = nulos_antes - nulos_despues
            if nulos_corregidos > 0:
                cleaning_steps.append(f"‚úÖ Se corrigieron {nulos_corregidos} datos faltantes")
            
            # 3. Validar y corregir tipos de datos
            tipos_corregidos = 0
            if 'price' in df_clean.columns:
                df_clean['price'] = pd.to_numeric(df_clean['price'], errors='coerce')
                tipos_corregidos += 1
            
            if 'bedrooms' in df_clean.columns:
                df_clean['bedrooms'] = pd.to_numeric(df_clean['bedrooms'], errors='coerce')
                tipos_corregidos += 1
                
            if 'bathrooms' in df_clean.columns:
                df_clean['bathrooms'] = pd.to_numeric(df_clean['bathrooms'], errors='coerce')
                tipos_corregidos += 1
            
            if 'sqft_living' in df_clean.columns:
                df_clean['sqft_living'] = pd.to_numeric(df_clean['sqft_living'], errors='coerce')
                tipos_corregidos += 1
            
            if tipos_corregidos > 0:
                cleaning_steps.append(f"‚úÖ Se corrigieron {tipos_corregidos} tipos de datos")
            
            # 4. Eliminar valores extremos poco realistas
            outliers_removidos = 0
            if 'price' in df_clean.columns:
                antes = len(df_clean)
                # Eliminar propiedades con precios irreales (menos de $1000 o m√°s de $50M)
                df_clean = df_clean[(df_clean['price'] >= 1000) & (df_clean['price'] <= 50000000)]
                outliers_removidos += antes - len(df_clean)
            
            if outliers_removidos > 0:
                cleaning_steps.append(f"‚úÖ Se eliminaron {outliers_removidos} propiedades con precios irreales")
            
            # Guardar dataset limpio
            clean_file_path = "data/dataset_limpio.csv"
            try:
                df_clean.to_csv(clean_file_path, index=False)
            except:
                pass  # No issue if can't save locally
            
            # Mostrar resultados
            st.success("‚úÖ ¬°Limpieza autom√°tica completada!")
            
            # Comparaci√≥n de salud del dataset
            st.subheader("üìä Comparaci√≥n: Antes vs Despu√©s")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**üìë Dataset Original**")
                st.metric("Total de propiedades", len(df_original_etl))
                st.metric("Datos faltantes", df_original_etl.isnull().sum().sum())
                st.metric("Propiedades duplicadas", len(df_original_etl[df_original_etl.duplicated()]))
                original_quality = ((len(df_original_etl) - df_original_etl.isnull().sum().sum()) / len(df_original_etl) * 100)
                st.metric("Calidad de datos", f"{original_quality:.1f}%")
            
            with col2:
                st.markdown("**‚ú® Dataset Limpio**")
                st.metric("Total de propiedades", len(df_clean), delta=len(df_clean) - len(df_original_etl))
                st.metric("Datos faltantes", df_clean.isnull().sum().sum(), 
                         delta=df_clean.isnull().sum().sum() - df_original_etl.isnull().sum().sum())
                st.metric("Propiedades duplicadas", len(df_clean[df_clean.duplicated()]),
                         delta=len(df_clean[df_clean.duplicated()]) - len(df_original_etl[df_original_etl.duplicated()]))
                clean_quality = ((len(df_clean) - df_clean.isnull().sum().sum()) / len(df_clean) * 100)
                st.metric("Calidad de datos", f"{clean_quality:.1f}%")
            
            # Resumen de lo que se hizo
            with st.expander("üîç Ver detalles de lo que se limpi√≥"):
                st.markdown("**Pasos de limpieza realizados:**")
                for step in cleaning_steps:
                    st.write(step)
                if not cleaning_steps:
                    st.write("‚ú® Los datos ya estaban en perfecto estado!")
            
            # Descargar dataset limpio
            csv_clean = df_clean.to_csv(index=False)
            st.download_button(
                label="‚¨áÔ∏è Descargar datos limpios",
                data=csv_clean,
                file_name="propiedades_limpias.csv",
                mime="text/csv"
            )
            
            # Guardar en session state para uso posterior
            st.session_state['df_clean'] = df_clean
            st.session_state['cleaning_completed'] = True
        
        # ----- SECCI√ìN DE FEATURE ENGINEERING -----
        st.markdown("---")
        st.header("‚öôÔ∏è 3. Feature Engineering")
        
        if st.button("üîß Crear Variables Calculadas", type="secondary"):
            df_to_process = st.session_state.df_clean if st.session_state.df_clean is not None else df
            df_engineered, new_features = create_calculated_features(df_to_process.copy())
            
            st.session_state.df_clean = df_engineered
            st.session_state.new_features = new_features
            
            st.success(f"‚úÖ {len(new_features)} nuevas variables creadas:")
            for feat in new_features:
                st.write(f"  ‚Ä¢ `{feat}`")
        
        # Mostrar dataset final
        if st.session_state.df_clean is not None:
            st.markdown("---")
            st.header("üìä 4. Dataset Procesado")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Filas finales", f"{st.session_state.df_clean.shape[0]:,}")
            with col2:
                st.metric("Columnas finales", st.session_state.df_clean.shape[1])
            with col3:
                st.metric("Nulos restantes", st.session_state.df_clean.isnull().sum().sum())
            
            with st.expander("üëÅÔ∏è Vista del dataset procesado"):
                st.dataframe(st.session_state.df_clean.head(20), use_container_width=True)

# ============================================================================
# M√ìDULO 2: EDA - VISUALIZACI√ìN DIN√ÅMICA
# ============================================================================
elif modulo == "üìä EDA - Visualizaciones":
    st.title("üìä M√≥dulo EDA: An√°lisis Exploratorio de Datos")
    
    # Verificar que hay datos
    df = st.session_state.df_clean if st.session_state.df_clean is not None else st.session_state.df_original
    
    if df is None:
        st.warning("‚ö†Ô∏è Por favor, primero carga datos en el m√≥dulo ETL")
        st.stop()
    
    # ----- FILTROS GLOBALES EN SIDEBAR -----
    st.sidebar.markdown("---")
    st.sidebar.subheader("üéõÔ∏è Filtros Globales")
    
    # Filtro de fecha
    if 'date' in df.columns:
        try:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            min_date = df['date'].min()
            max_date = df['date'].max()
            if pd.notna(min_date) and pd.notna(max_date):
                date_range = st.sidebar.date_input(
                    "Rango de fechas:",
                    value=(min_date.date(), max_date.date()),
                    min_value=min_date.date(),
                    max_value=max_date.date()
                )
                if len(date_range) == 2:
                    df = df[(df['date'].dt.date >= date_range[0]) & (df['date'].dt.date <= date_range[1])]
        except:
            pass
    
    # Filtro de categor√≠a (ciudad)
    if 'city' in df.columns:
        cities = ["Todas"] + sorted(df['city'].dropna().unique().tolist())
        selected_city = st.sidebar.selectbox("Ciudad:", cities)
        if selected_city != "Todas":
            df = df[df['city'] == selected_city]
    
    # Filtro num√©rico (slider de precio)
    if 'price' in df.columns:
        price_min = float(df['price'].min()) if pd.notna(df['price'].min()) else 0
        price_max = float(df['price'].max()) if pd.notna(df['price'].max()) else 1000000
        price_range = st.sidebar.slider(
            "Rango de Precio ($):",
            min_value=price_min,
            max_value=price_max,
            value=(price_min, price_max),
            format="$%,.0f"
        )
        df = df[(df['price'] >= price_range[0]) & (df['price'] <= price_range[1])]
    
    st.info(f"üìä Mostrando {len(df):,} registros despu√©s de aplicar filtros")
    
    # ----- PESTA√ëAS DE AN√ÅLISIS -----
    tab1, tab2, tab3 = st.tabs(["üìà An√°lisis Univariado", "üîó An√°lisis Bivariado", "üìë Reporte"])
    
    # ----- TAB 1: AN√ÅLISIS UNIVARIADO -----
    with tab1:
        st.subheader("An√°lisis Univariado")
        
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) > 0:
            selected_col = st.selectbox("Selecciona una variable num√©rica:", numeric_cols)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Histograma con Plotly
                fig_hist = px.histogram(
                    df, x=selected_col, nbins=30,
                    title=f"Distribuci√≥n de {selected_col}",
                    color_discrete_sequence=["#F7B500"]
                )
                fig_hist.update_layout(
                    xaxis_title=selected_col,
                    yaxis_title="Frecuencia",
                    template="plotly_white"
                )
                st.plotly_chart(fig_hist, use_container_width=True)
            
            with col2:
                # Boxplot con Plotly
                fig_box = px.box(
                    df, y=selected_col,
                    title=f"Boxplot de {selected_col}",
                    color_discrete_sequence=["#001E62"]
                )
                fig_box.update_layout(template="plotly_white")
                st.plotly_chart(fig_box, use_container_width=True)
            
            # Estad√≠sticas descriptivas
            with st.expander("üìä Estad√≠sticas Descriptivas"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Media", f"{df[selected_col].mean():,.2f}")
                with col2:
                    st.metric("Mediana", f"{df[selected_col].median():,.2f}")
                with col3:
                    st.metric("Desv. Est√°ndar", f"{df[selected_col].std():,.2f}")
                with col4:
                    st.metric("Nulos", df[selected_col].isnull().sum())
        else:
            st.warning("No hay columnas num√©ricas para analizar")
    
    # ----- TAB 2: AN√ÅLISIS BIVARIADO -----
    with tab2:
        st.subheader("An√°lisis Bivariado")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Heatmap de correlaciones
            st.markdown("#### üî• Matriz de Correlaciones")
            numeric_df = df.select_dtypes(include=[np.number])
            if len(numeric_df.columns) > 1:
                corr_matrix = numeric_df.corr()
                
                fig_corr = px.imshow(
                    corr_matrix,
                    text_auto=".2f",
                    aspect="auto",
                    color_continuous_scale="RdYlBu_r",
                    title="Correlaci√≥n entre Variables"
                )
                fig_corr.update_layout(height=500)
                st.plotly_chart(fig_corr, use_container_width=True)
            else:
                st.warning("Se necesitan al menos 2 columnas num√©ricas")
        
        with col2:
            # Scatter plot
            st.markdown("#### üìç Relaci√≥n entre Variables")
            if len(numeric_cols) >= 2:
                x_var = st.selectbox("Variable X:", numeric_cols, index=0)
                y_var = st.selectbox("Variable Y:", numeric_cols, index=min(1, len(numeric_cols)-1))
                
                fig_scatter = px.scatter(
                    df, x=x_var, y=y_var,
                    color='waterfront' if 'waterfront' in df.columns else None,
                    title=f"{y_var} vs {x_var}",
                    color_discrete_sequence=["#001E62", "#F7B500"]
                )
                fig_scatter.update_layout(template="plotly_white")
                st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Evoluci√≥n temporal
        st.markdown("---")
        st.markdown("#### üìÖ Evoluci√≥n Temporal")
        
        if 'date' in df.columns and 'price' in df.columns:
            df_time = df.dropna(subset=['date', 'price']).copy()
            df_time['date'] = pd.to_datetime(df_time['date'], errors='coerce')
            df_time = df_time.dropna(subset=['date'])
            
            if len(df_time) > 0:
                df_time = df_time.set_index('date').resample('M')['price'].mean().reset_index()
                
                fig_time = px.area(
                    df_time, x='date', y='price',
                    title="Precio Promedio Mensual",
                    color_discrete_sequence=["#F7B500"]
                )
                fig_time.update_layout(
                    xaxis_title="Fecha",
                    yaxis_title="Precio Promedio ($)",
                    template="plotly_white"
                )
                st.plotly_chart(fig_time, use_container_width=True)
            else:
                st.warning("No hay datos suficientes para el gr√°fico temporal")
        else:
            st.info("Se requiere columna 'date' y 'price' para el an√°lisis temporal")
    
    # ----- TAB 3: REPORTE -----
    with tab3:
        st.subheader("üìë Reporte Ejecutivo")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("### üìä Resumen del Dataset")
            st.dataframe(df.describe(), use_container_width=True)
        
        with col2:
            st.markdown("### üìà KPIs Principales")
            if 'price' in df.columns:
                st.metric("Precio Promedio", f"${df['price'].mean():,.0f}")
                st.metric("Precio Mediano", f"${df['price'].median():,.0f}")
            if 'sqft_living' in df.columns:
                st.metric("√Årea Promedio (sqft)", f"{df['sqft_living'].mean():,.0f}")
            st.metric("Total Propiedades", f"{len(df):,}")
        
        # Gr√°fico comparativo por ciudad
        if 'city' in df.columns and 'price' in df.columns:
            st.markdown("---")
            st.markdown("### üèôÔ∏è Precio por Ciudad (Top 10)")
            
            city_prices = df.groupby('city')['price'].agg(['mean', 'count']).reset_index()
            city_prices = city_prices.nlargest(10, 'mean')
            
            fig_cities = px.bar(
                city_prices, x='city', y='mean',
                title="Precio Promedio por Ciudad",
                color='count',
                color_continuous_scale="Blues",
                labels={'mean': 'Precio Promedio ($)', 'city': 'Ciudad', 'count': 'Cantidad'}
            )
            fig_cities.update_layout(template="plotly_white")
            st.plotly_chart(fig_cities, use_container_width=True)
        
        # Respuestas a preguntas de negocio
        st.markdown("---")
        st.markdown("### üéØ Respuestas a Preguntas de Negocio")
        
        with st.expander("1. ¬øQu√© factores correlacionan m√°s con el precio?"):
            if 'price' in df.columns:
                correlations = df.select_dtypes(include=[np.number]).corr()['price'].drop('price').sort_values(ascending=False)
                st.write("**Top 5 factores correlacionados con el precio:**")
                for i, (col, corr) in enumerate(correlations.head(5).items(), 1):
                    st.write(f"{i}. {col}: {corr:.3f}")
        
        with st.expander("2. ¬øExiste estacionalidad en los precios?"):
            if 'mes' in df.columns and 'price' in df.columns:
                monthly_avg = df.groupby('mes')['price'].mean()
                st.line_chart(monthly_avg)
                st.write(f"Mes con mayor precio promedio: {monthly_avg.idxmax()}")
                st.write(f"Mes con menor precio promedio: {monthly_avg.idxmin()}")
            else:
                st.info("Ejecuta Feature Engineering en ETL para ver an√°lisis de estacionalidad")
        
        with st.expander("3. ¬øImpacto de waterfront en el precio?"):
            if 'waterfront' in df.columns and 'price' in df.columns:
                wf_analysis = df.groupby('waterfront')['price'].agg(['mean', 'median', 'count'])
                wf_analysis.index = ['Sin vista al agua', 'Con vista al agua']
                st.dataframe(wf_analysis)
                
                if len(wf_analysis) == 2:
                    diff = wf_analysis.loc['Con vista al agua', 'mean'] - wf_analysis.loc['Sin vista al agua', 'mean']
                    pct = (diff / wf_analysis.loc['Sin vista al agua', 'mean']) * 100
                    st.success(f"üìà Las propiedades con vista al agua cuestan en promedio ${diff:,.0f} m√°s ({pct:.1f}%)")

# ============================================================================
# SECCI√ìN DE VERIFICACI√ìN DE DATOS (TEMPORAL)
# ============================================================================
elif modulo == "üîç VERIFICACI√ìN (Temporal)":
    st.title("üîç VERIFICACI√ìN DE DATOS (Para Revisi√≥n)")
    st.warning("‚ö†Ô∏è SECCI√ìN TEMPORAL: Esta secci√≥n se eliminar√° una vez verificados todos los c√°lculos")
    
    # Verificar que hay datos
    df = st.session_state.df_clean if st.session_state.df_clean is not None else st.session_state.df_original
    
    if df is None:
        st.error("‚ùå No hay datos cargados. Por favor, primero usa el m√≥dulo ETL.")
        st.stop()
    
    st.markdown("**üí° Datos importantes para copiar y verificar:**")
    
    # M√©tricas clave calculadas
    col1, col2, col3, col4 = st.columns(4)
    
    precio_promedio = df['price'].mean() if 'price' in df.columns else 0
    precio_mediano = df['price'].median() if 'price' in df.columns else 0
    total_propiedades = len(df)
    precio_maximo = df['price'].max() if 'price' in df.columns else 0
    precio_minimo = df['price'].min() if 'price' in df.columns else 0
    
    with col1:
        st.metric("Precio Promedio", f"${precio_promedio:,.0f}")
        st.metric("Precio Mediano", f"${precio_mediano:,.0f}")
    
    with col2:
        st.metric("Total Propiedades", f"{total_propiedades:,}")
        st.metric("Precio M√°ximo", f"${precio_maximo:,.0f}")
    
    with col3:
        if 'bedrooms' in df.columns:
            habitaciones_promedio = df['bedrooms'].mean()
            st.metric("Habitaciones Promedio", f"{habitaciones_promedio:.1f}")
        
        if 'bathrooms' in df.columns:
            banos_promedio = df['bathrooms'].mean()
            st.metric("Ba√±os Promedio", f"{banos_promedio:.1f}")
    
    with col4:
        if 'sqft_living' in df.columns:
            area_promedio = df['sqft_living'].mean()
            st.metric("√Årea Promedio (sqft)", f"{area_promedio:,.0f}")
        
        st.metric("Precio M√≠nimo", f"${precio_minimo:,.0f}")
    
    # Datos para copiar
    st.subheader("üìã Datos para Copiar y Verificar")
    
    verification_data = f"""**M√âTRICAS PRINCIPALES:**
- Total de propiedades: {total_propiedades:,}
- Precio promedio: ${precio_promedio:,.2f}
- Precio mediano: ${precio_mediano:,.2f}
- Precio m√°ximo: ${precio_maximo:,.2f}
- Precio m√≠nimo: ${precio_minimo:,.2f}
    """
    
    if 'bedrooms' in df.columns:
        verification_data += f"\n- Habitaciones promedio: {df['bedrooms'].mean():.2f}"
    if 'bathrooms' in df.columns:
        verification_data += f"\n- Ba√±os promedio: {df['bathrooms'].mean():.2f}"
    if 'sqft_living' in df.columns:
        verification_data += f"\n- √Årea promedio: {df['sqft_living'].mean():.2f} sqft"
    
    # Top 5 precios m√°s altos
    if 'price' in df.columns:
        top_prices = df.nlargest(5, 'price')[['price']]
        verification_data += f"\n\n**TOP 5 PRECIOS M√ÅS ALTOS:**\n"
        for i, (_, row) in enumerate(top_prices.iterrows(), 1):
            verification_data += f"{i}. ${row['price']:,.2f}\n"
    
    # Distribuci√≥n por rangos
    if 'price' in df.columns:
        ranges = [(0, 200000), (200000, 500000), (500000, 1000000), (1000000, float('inf'))]
        verification_data += f"\n**DISTRIBUCI√ìN POR RANGOS:**\n"
        for min_p, max_p in ranges:
            count = len(df[(df['price'] >= min_p) & (df['price'] < max_p)])
            percentage = (count / len(df)) * 100
            range_name = f"${min_p:,} - ${max_p:,}" if max_p != float('inf') else f"M√°s de ${min_p:,}"
            verification_data += f"- {range_name}: {count:,} propiedades ({percentage:.1f}%)\n"
    
    st.text_area(
        "Datos calculados (copiar para verificaci√≥n):",
        verification_data,
        height=400
    )
    
    # Vista previa de datos crudos
    with st.expander("üîç Ver muestra de datos procesados"):
        st.dataframe(df.head(10))
    
    # Verificaci√≥n de columnas espec√≠ficas
    st.subheader("üìä Informaci√≥n de Columnas")
    if not df.empty:
        for col in df.columns:
            if df[col].dtype in ['int64', 'float64']:
                col_data = {
                    'Columna': col,
                    'Tipo': str(df[col].dtype),
                    'Min': f"{df[col].min():,.2f}" if pd.notnull(df[col].min()) else "N/A",
                    'Max': f"{df[col].max():,.2f}" if pd.notnull(df[col].max()) else "N/A",
                    'Promedio': f"{df[col].mean():.2f}" if pd.notnull(df[col].mean()) else "N/A",
                    'Nulos': df[col].isnull().sum()
                }
                st.write(f"**{col}:** Min: {col_data['Min']}, Max: {col_data['Max']}, Promedio: {col_data['Promedio']}, Nulos: {col_data['Nulos']}")

# ============================================================================
# M√ìDULO 3: INTEGRACI√ìN CON IA (GROQ)
# ============================================================================
elif modulo == "ü§ñ IA - Insights Inteligentes":
    st.title("ü§ñ M√≥dulo IA: Insights de Negocio con Inteligencia Artificial")
    st.markdown("**¬øQu√© hace esta secci√≥n?** Usa inteligencia artificial para responder preguntas de negocio sobre las propiedades.")
    
    # Verificar que hay datos
    df = st.session_state.df_clean if st.session_state.df_clean is not None else st.session_state.df_original
    
    if df is None:
        st.warning("‚ö†Ô∏è Por favor, primero carga datos en el m√≥dulo ETL")
        st.stop()
    
    # Configuraci√≥n de API simplificada
    st.markdown("### üîê Configuraci√≥n de API")
    
    api_key = st.text_input(
        "üîë Clave de API de Groq (opcional):",
        type="password",
        help="Obt√©n tu clave gratuita en https://console.groq.com/ para activar el an√°lisis con IA"
    )
    
    if api_key:
        # Preguntas de negocio orientadas a proyecci√≥n comercial
        st.markdown("---")
        st.markdown("### üéØ Preguntas de Negocio")
        
        # Definir preguntas m√°s orientadas al negocio
        business_questions = {
            "Oportunidades de Inversi√≥n": {
                "question": "¬øEn qu√© √°reas puedo encontrar las mejores propiedades por el precio?",
                "description": "Identifica zonas con propiedades de buen valor para inversi√≥n"
            },
            "Proyecci√≥n de Ventas": {
                "question": "¬øCu√°l ser√≠a el precio ideal para vender mi propiedad?",
                "description": "Estima precios de venta basado en caracter√≠sticas similares"
            },
            "An√°lisis de Mercado": {
                "question": "¬øQu√© tipo de propiedades son m√°s populares y rentables?",
                "description": "Analiza tendencias de demanda por tipo de propiedad"
            },
            "Comparativa Regional": {
                "question": "¬øD√≥nde est√°n las propiedades m√°s caras vs m√°s baratas?",
                "description": "Compara precios promedio por ubicaci√≥n"
            },
            "Retorno de Inversi√≥n": {
                "question": "¬øQu√© propiedades me dar√≠an mejor retorno si las compro para rentar?",
                "description": "Calcula potencial de retorno para inversi√≥n en alquiler"
            }
        }
        
        selected_question = st.selectbox(
            "Selecciona una pregunta de negocio:",
            options=list(business_questions.keys()),
            format_func=lambda x: f"üìä {x}: {business_questions[x]['question']}"
        )
        
        if selected_question:
            st.info(f"üí° {business_questions[selected_question]['description']}")
        
        # Bot√≥n para an√°lisis espec√≠fico
        if st.button("üìä Analizar Pregunta de Negocio", type="primary"):
            if not api_key:
                st.error("‚ùå Por favor, ingresa tu clave de API de Groq")
            else:
                selected_q_data = business_questions[selected_question]
                with st.spinner("ü§î La IA est√° analizando tu pregunta de negocio..."):
                    # Crear prompt espec√≠fico para la pregunta
                    prompt = f"""
                    Analiza estos datos de propiedades inmobiliarias para responder esta pregunta de negocio:
                    
                    PREGUNTA: {selected_q_data['question']}
                    CONTEXTO: {selected_q_data['description']}
                    
                    Datos disponibles:
                    - {len(df)} propiedades
                    - Precio promedio: ${df['price'].mean():,.0f} (si tiene columna price)
                    
                    Por favor responde de forma pr√°ctica y orientada a decisiones de negocio.
                    """
                    
                    insights, error = generate_ai_insights(df, api_key, custom_prompt=prompt)
                    
                    if error:
                        st.error(f"‚ùå Error: {error}")
                    else:
                        st.success("‚úÖ An√°lisis completado")
                        st.markdown("### üéØ Respuesta de Negocio")
                        st.markdown(insights)
        
        # An√°lisis autom√°tico completo
        st.markdown("---")
        st.markdown("### üöÄ An√°lisis Completo Autom√°tico")
        
        if st.button("üîç Generar Reporte Completo", type="secondary"):
            with st.spinner("ü§ñ Generando reporte completo con IA..."):
                insights, error = generate_ai_insights(df, api_key)
                
                if error:
                    st.error(f"‚ùå Error: {error}")
                else:
                    st.success("‚úÖ Reporte generado")
                    st.markdown("### üìä Insights Completos")
                    st.markdown(insights)
                    
                    # Descargar reporte
                    st.download_button(
                        label="‚¨áÔ∏è Descargar reporte completo",
                        data=insights,
                        file_name=f"reporte_ia_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                        mime="text/plain"
                    )
        
        # Chat interactivo personalizado
        st.markdown("---")
        st.markdown("### üí¨ Consultas Personalizadas")
        st.markdown("**Haz preguntas espec√≠ficas sobre las propiedades:**")
        
        user_question = st.text_input(
            "Tu pregunta:",
            placeholder="¬øCu√°les son las mejores zonas para invertir con poco presupuesto?"
        )
        
        if user_question and st.button("üì§ Obtener Respuesta"):
            with st.spinner("üí≠ Analizando tu pregunta..."):
                prompt = f"""
                Usuario pregunta: {user_question}
                
                Analiza los datos de propiedades inmobiliarias y responde de forma clara y pr√°ctica.
                Enf√≥cate en dar consejos √∫tiles para decisiones de negocio.
                """
                answer, error = generate_ai_insights(df, api_key, custom_prompt=prompt)
                
                if error:
                    st.error(f"‚ùå Error: {error}")
                else:
                    st.markdown("**ü§ñ Respuesta:**")
                    st.markdown(answer)
    
    else:
        st.info("üí° Para usar el an√°lisis con IA, ingresa tu clave de API de Groq (es gratuita)")
        
        # Mostrar m√©tricas b√°sicas sin IA
        st.markdown("### üìä Resumen B√°sico de Datos")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Propiedades", f"{len(df):,}")
        with col2:
            st.metric("Variables Disponibles", df.shape[1])
        with col3:
            if 'price' in df.columns:
                st.metric("Precio Promedio", f"${df['price'].mean():,.0f}")

# ============================================================================
# M√ìDULO 4: INTEGRACI√ìN CON IA (GROQ) - ANTERIOR
# ============================================================================
elif modulo == "ü§ñ IA - Insights Inteligentes (OLD)":
    st.title("ü§ñ M√≥dulo IA: Insights Generados con Inteligencia Artificial")
    st.markdown("Usa el poder de los modelos de lenguaje para obtener an√°lisis avanzados.")
    
    # Verificar que hay datos
    df = st.session_state.df_clean if st.session_state.df_clean is not None else st.session_state.df_original
    
    if df is None:
        st.warning("‚ö†Ô∏è Por favor, primero carga datos en el m√≥dulo ETL")
        st.stop()
    
    # Configuraci√≥n de API
    st.markdown("### üîê Configuraci√≥n de API")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        api_key = st.text_input(
            "Ingresa tu API Key de Groq:",
            type="password",
            help="Obt√©n tu API key en https://console.groq.com"
        )
    with col2:
        st.markdown("")
        st.markdown("")
        st.link_button("üîë Obtener API Key", "https://console.groq.com")
    
    # Mostrar resumen de datos actuales
    st.markdown("---")
    st.markdown("### üìä Datos para Analizar")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Registros", f"{len(df):,}")
        st.metric("Variables", df.shape[1])
    with col2:
        st.metric("Valores Nulos", df.isnull().sum().sum())
        if 'price' in df.columns:
            st.metric("Precio Promedio", f"${df['price'].mean():,.0f}")
    
    with st.expander("üìã Resumen Estad√≠stico (se enviar√° al LLM)"):
        st.dataframe(df.describe(), use_container_width=True)
    
    # Bot√≥n para generar insights
    st.markdown("---")
    st.markdown("### üéØ Generar An√°lisis con IA")
    
    if st.button("üöÄ Generar Insights con IA", type="primary", use_container_width=True):
        if not api_key:
            st.error("‚ùå Por favor, ingresa tu API Key de Groq")
        else:
            with st.spinner("ü§î Analizando datos con IA... (esto puede tomar unos segundos)"):
                insights, error = generate_ai_insights(df, api_key)
                
                if error:
                    st.error(f"‚ùå Error al generar insights: {error}")
                else:
                    st.success("‚úÖ An√°lisis completado")
                    st.markdown("---")
                    st.markdown("### üí° Insights Generados por IA")
                    st.markdown(insights)
                    
                    # Guardar insights en session state
                    st.session_state.last_insights = insights
    
    # Mostrar √∫ltimos insights si existen
    if 'last_insights' in st.session_state and st.session_state.last_insights:
        with st.expander("üìú √öltimos Insights Generados"):
            st.markdown(st.session_state.last_insights)
    
    # Informaci√≥n adicional
    st.markdown("---")
    st.info("""
    üí° **¬øC√≥mo funciona?**
    1. Se toma el resumen estad√≠stico (`df.describe()`) de tus datos
    2. Se construye un prompt estructurado con contexto de negocio
    3. Se env√≠a a la API de Groq (modelo Llama-3)
    4. El LLM analiza los patrones y devuelve insights accionables
    """)

# ============================================================================
# FOOTER
# ============================================================================
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666;'>
        <p>üè† Dashboard de An√°lisis Inmobiliario | Universidad EAFIT 2026-1</p>
        <p>Fundamentos de Ciencia de Datos | Prof. Jorge Iv√°n Padilla-Buritic√°</p>
    </div>
    """,
    unsafe_allow_html=True
)
